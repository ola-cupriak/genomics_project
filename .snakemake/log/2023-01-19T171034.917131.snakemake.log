Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                count    min threads    max threads
---------------  -------  -------------  -------------
all                    1              1              1
build_supertree        1              1              1
total                  2              1              1

Select jobs to execute...

[Thu Jan 19 17:10:35 2023]
rule build_supertree:
    input: results/all05_orto10random_trees1file.nwk
    output: results/all05_orto10random_supertree.nwk
    jobid: 1
    reason: Missing output files: results/all05_orto10random_supertree.nwk
    wildcards: subset=all05, type=orto10random
    resources: tmpdir=/tmp

[Thu Jan 19 17:10:35 2023]
Error in rule build_supertree:
    jobid: 1
    input: results/all05_orto10random_trees1file.nwk
    output: results/all05_orto10random_supertree.nwk
    shell:
        
        var=$(fasturec -G results/all05_orto10random_trees1file.nwk -Z | tail -1 | cut -d"-" -f2 | cut -d" " -f1)
        head -n 1 $var | cut -d' ' -f2 > results/all05_orto10random_supertree.nwk
        rm $var
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2023-01-19T171034.917131.snakemake.log
